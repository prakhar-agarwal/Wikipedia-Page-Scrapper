# Wikipedia-Page-Scrapper
Given a link to a wiki page, the code scrapes that page and saves the data and relevant metadata appropriately using multiple threads. Also, for any 10 random links on the page (links to other wiki   pages only),  scrapy scrapes the content and saves it appropriately. Data is saved in a way that makes consumption of that data as simple as possible for the end user.   Starting URL can be chosen by the user.
